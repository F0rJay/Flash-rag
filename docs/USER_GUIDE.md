# ğŸ“– LegalFlash-RAG å®Œæ•´ä½¿ç”¨æ‰‹å†Œ

> **å‚»ç“œå¼æ•™ç¨‹**ï¼šä»é›¶å¼€å§‹ï¼Œä¸€æ­¥æ­¥å¸¦ä½ å®Œæˆæ¨¡å‹è®­ç»ƒã€éƒ¨ç½²å’Œå‹æµ‹

---

## ğŸ“‹ ç›®å½•

1. [ç¯å¢ƒå‡†å¤‡](#1-ç¯å¢ƒå‡†å¤‡)
2. [æ•°æ®å‡†å¤‡](#2-æ•°æ®å‡†å¤‡)
3. [æ¨¡å‹è®­ç»ƒ](#3-æ¨¡å‹è®­ç»ƒ)
4. [æƒé‡åˆå¹¶](#4-æƒé‡åˆå¹¶)
5. [æ„å»º RAG çŸ¥è¯†åº“](#5-æ„å»º-rag-çŸ¥è¯†åº“)
6. [å¯åŠ¨æ¨ç†æœåŠ¡](#6-å¯åŠ¨æ¨ç†æœåŠ¡)
7. [å¯åŠ¨ API æœåŠ¡](#7-å¯åŠ¨-api-æœåŠ¡)
8. [å¯åŠ¨å‰ç«¯ç•Œé¢](#8-å¯åŠ¨å‰ç«¯ç•Œé¢)
9. [Docker éƒ¨ç½²](#9-docker-éƒ¨ç½²)
10. [æ€§èƒ½å‹æµ‹](#10-æ€§èƒ½å‹æµ‹)

---

## 1. ç¯å¢ƒå‡†å¤‡

### 1.1 å®‰è£…ä¾èµ–

```bash
# è¿›å…¥é¡¹ç›®ç›®å½•
cd /root/autodl-tmp/flash-rag

# å®‰è£…æ‰€æœ‰ä¾èµ–ï¼ˆæ¨èä½¿ç”¨å›½å†…é•œåƒï¼‰
pip install -i https://pypi.tuna.tsinghua.edu.cn/simple -r requirements.txt

# å¦‚æœé‡åˆ° bitsandbytes å®‰è£…é—®é¢˜ï¼Œå•ç‹¬å®‰è£…
pip install -i https://pypi.tuna.tsinghua.edu.cn/simple --trusted-host pypi.tuna.tsinghua.edu.cn bitsandbytes
```

### 1.2 éªŒè¯å®‰è£…

```bash
# æ£€æŸ¥æ ¸å¿ƒä¾èµ–
python -c "import torch; import transformers; import vllm; print('âœ… æ ¸å¿ƒä¾èµ–å®‰è£…æˆåŠŸ')"
```

### 1.3 å‡†å¤‡æ•°æ®æ–‡ä»¶

ç¡®ä¿ä½ æœ‰ä»¥ä¸‹ DISC-Law æ•°æ®é›†æ–‡ä»¶ï¼ˆæ”¾åœ¨é¡¹ç›®æ ¹ç›®å½•æˆ– `data/` ç›®å½•ä¸‹ï¼‰ï¼š
- `DISC-Law-SFT-Pair-QA-released.jsonl` - ç”¨äºè®­ç»ƒ
- `DISC-Law-SFT-Triplet-QA-released.jsonl` - ç”¨äºæ„å»º RAG çŸ¥è¯†åº“
- `DISC-Law-SFT-Triplet-released.jsonl` - ç”¨äºæ„å»º RAG çŸ¥è¯†åº“
- `DISC-Law-SFT-Pair.jsonl` - ç”¨äºæ„å»º RAG çŸ¥è¯†åº“

---

## 2. æ•°æ®å‡†å¤‡

### 2.1 è½¬æ¢å’Œåˆ’åˆ†è®­ç»ƒæ•°æ®é›†

**æ­¥éª¤ 1ï¼šå‡†å¤‡è®­ç»ƒæ•°æ®**

```bash
# å°† DISC-Law æ ¼å¼è½¬æ¢ä¸ºé¡¹ç›®æ ¼å¼ï¼Œå¹¶åˆ’åˆ†è®­ç»ƒé›†/éªŒè¯é›†/æµ‹è¯•é›†
python scripts/prepare_dataset.py DISC-Law-SFT-Pair-QA-released.jsonl \
    --train-ratio 0.8 \
    --val-ratio 0.1 \
    --test-ratio 0.1
```

**è¾“å‡ºæ–‡ä»¶ï¼š**
- `data/datasets/train.jsonl` - è®­ç»ƒé›†ï¼ˆ80%ï¼‰
- `data/datasets/val.jsonl` - éªŒè¯é›†ï¼ˆ10%ï¼‰
- `data/datasets/test.jsonl` - æµ‹è¯•é›†ï¼ˆ10%ï¼‰

**å¦‚æœå·²æœ‰åˆ’åˆ†å¥½çš„æ•°æ®é›†ï¼Œå¯ä»¥ç›´æ¥ä½¿ç”¨ï¼š**

```bash
# ä½¿ç”¨ç°æœ‰æ–‡ä»¶ï¼Œè·³è¿‡è½¬æ¢
python scripts/prepare_dataset.py --use-existing
```

### 2.2 éªŒè¯æ•°æ®é›†æ ¼å¼

```bash
# éªŒè¯æ•°æ®é›†æ ¼å¼æ˜¯å¦æ­£ç¡®
python scripts/prepare_dataset.py --validate
```

### 2.3 åˆ†ææ•°æ®é›†ï¼ˆå¯é€‰ï¼‰

```bash
# åˆ†ææ•°æ®é›†ç»Ÿè®¡ä¿¡æ¯
python scripts/analyze_dataset.py data/datasets/train.jsonl
```

---

## 3. æ¨¡å‹è®­ç»ƒ

### 3.1 æ£€æŸ¥è®­ç»ƒé…ç½®

ç¼–è¾‘ `config/train_config.yaml`ï¼Œç¡®è®¤ä»¥ä¸‹å…³é”®å‚æ•°ï¼š

```yaml
model:
  name: "hfl/llama-3-chinese-8b-instruct-v3"  # åŸºç¡€æ¨¡å‹
  max_seq_length: 2048  # æ ¹æ®æ˜¾å­˜è°ƒæ•´

quantization:
  load_in_4bit: true  # å¯ç”¨ 4-bit é‡åŒ–ï¼ˆèŠ‚çœæ˜¾å­˜ï¼‰

training:
  num_train_epochs: 3  # è®­ç»ƒè½®æ•°
  per_device_train_batch_size: 8  # æ‰¹æ¬¡å¤§å°ï¼ˆæ ¹æ®æ˜¾å­˜è°ƒæ•´ï¼‰
```

### 3.2 å¼€å§‹è®­ç»ƒ

```bash
# å¯åŠ¨è®­ç»ƒï¼ˆå• GPUï¼‰
python train.py

# å¦‚æœä½¿ç”¨å¤š GPUï¼Œå¯ä»¥ä½¿ç”¨ accelerate
accelerate launch train.py
```

**è®­ç»ƒè¿‡ç¨‹ï¼š**
- è®­ç»ƒæ—¥å¿—ä¼šè¾“å‡ºåˆ°æ§åˆ¶å°
- TensorBoard æ—¥å¿—ä¿å­˜åœ¨ `output/logs/`
- è®­ç»ƒæ£€æŸ¥ç‚¹ä¿å­˜åœ¨ `output/checkpoint-*/`
- GPU ç›‘æ§æ•°æ®ä¼šè®°å½•åˆ° TensorBoard

### 3.3 æŸ¥çœ‹è®­ç»ƒè¿›åº¦ï¼ˆå¯é€‰ï¼‰

**æ‰“å¼€æ–°ç»ˆç«¯ï¼Œå¯åŠ¨ TensorBoardï¼š**

```bash
bash scripts/view_training.sh
# æˆ–æ‰‹åŠ¨å¯åŠ¨
tensorboard --logdir output/logs --port 6006
```

ç„¶ååœ¨æµè§ˆå™¨æ‰“å¼€ `http://localhost:6006` æŸ¥çœ‹ï¼š
- æŸå¤±æ›²çº¿
- å­¦ä¹ ç‡å˜åŒ–
- GPU ä½¿ç”¨ç‡
- è®­ç»ƒé€Ÿåº¦

### 3.4 è®­ç»ƒå®Œæˆæ£€æŸ¥

è®­ç»ƒå®Œæˆåï¼Œæ£€æŸ¥è¾“å‡ºç›®å½•ï¼š

```bash
ls -lh output/
# åº”è¯¥çœ‹åˆ°ç±»ä¼¼ï¼š
# - checkpoint-1/
# - checkpoint-2/
# - checkpoint-3/
# - logs/
```

---

## 4. æƒé‡åˆå¹¶

**âš ï¸ é‡è¦ï¼šè®­ç»ƒå®Œæˆåå¿…é¡»åˆå¹¶æƒé‡ï¼Œå¦åˆ™ vLLM æ— æ³•ä½¿ç”¨ï¼**

### 4.1 åˆå¹¶ LoRA æƒé‡åˆ°åŸºç¡€æ¨¡å‹

```bash
# åˆå¹¶æƒé‡ï¼ˆä½¿ç”¨æœ€æ–°çš„æ£€æŸ¥ç‚¹ï¼‰
python merge.py

# æˆ–è€…æŒ‡å®šæ£€æŸ¥ç‚¹è·¯å¾„
python merge.py --checkpoint output/checkpoint-3
```

**è¾“å‡ºï¼š**
- åˆå¹¶åçš„æ¨¡å‹ä¿å­˜åœ¨ `output/llama3-law-merged/`
- åŒ…å«å®Œæ•´çš„æ¨¡å‹æƒé‡ï¼ˆ`.safetensors` æ–‡ä»¶ï¼‰

### 4.2 éªŒè¯åˆå¹¶ç»“æœ

```bash
# æ£€æŸ¥åˆå¹¶åçš„æ¨¡å‹æ–‡ä»¶
ls -lh output/llama3-law-merged/
# åº”è¯¥çœ‹åˆ°ï¼š
# - config.json
# - model.safetensors (æˆ– model-*.safetensors)
# - tokenizer.json
# - ...
```

---

## 5. æ„å»º RAG çŸ¥è¯†åº“

### 5.1 æå–çŸ¥è¯†åº“å†…å®¹

**æ­¥éª¤ 1ï¼šæå–æ³•æ¡å‹çŸ¥è¯†åº“ï¼ˆä» reference å­—æ®µï¼‰**

```bash
python scripts/prepare_rag_knowledge.py \
    DISC-Law-SFT-Triplet-QA-released.jsonl \
    --mode law \
    --output data/docs/legal_docs.txt
```

**æ­¥éª¤ 2ï¼šæå–æ¡ˆä¾‹å‹çŸ¥è¯†åº“ï¼ˆä» input + outputï¼‰**

```bash
python scripts/prepare_rag_knowledge.py \
    DISC-Law-SFT-Triplet-QA-released.jsonl \
    --mode case \
    --output data/docs/case_docs.txt
```

**æ­¥éª¤ 3ï¼šæå–åˆ¤å†³ä¹¦å‹çŸ¥è¯†åº“ï¼ˆä» input å­—æ®µï¼‰**

```bash
python scripts/prepare_rag_knowledge.py \
    DISC-Law-SFT-Pair.jsonl \
    --mode judgement \
    --output data/docs/judgement_docs.txt
```

### 5.2 æ„å»ºå‘é‡æ•°æ®åº“

**æ­¥éª¤ 1ï¼šæ„å»ºæ³•æ¡å‹å‘é‡æ•°æ®åº“**

```bash
python ingest.py \
    --docs_path data/docs/legal_docs.txt \
    --knowledge_type law \
    --chunk_size 500 \
    --chunk_overlap 50
```

**æ­¥éª¤ 2ï¼šæ„å»ºæ¡ˆä¾‹å‹å‘é‡æ•°æ®åº“**

```bash
python ingest.py \
    --docs_path data/docs/case_docs.txt \
    --knowledge_type case \
    --chunk_size 1000 \
    --chunk_overlap 100
```

**æ­¥éª¤ 3ï¼šæ„å»ºåˆ¤å†³ä¹¦å‹å‘é‡æ•°æ®åº“**

```bash
python ingest.py \
    --docs_path data/docs/judgement_docs.txt \
    --knowledge_type judgement \
    --chunk_size 2000 \
    --chunk_overlap 200
```

**è¾“å‡ºï¼š**
- `chroma_db/` - æ³•æ¡å‹å‘é‡æ•°æ®åº“
- `chroma_db_case/` - æ¡ˆä¾‹å‹å‘é‡æ•°æ®åº“
- `chroma_db_judgement/` - åˆ¤å†³ä¹¦å‹å‘é‡æ•°æ®åº“

---

## 6. å¯åŠ¨æ¨ç†æœåŠ¡

### 6.1 å¯åŠ¨ vLLM æœåŠ¡

**æ‰“å¼€ç»ˆç«¯ 1ï¼š**

```bash
# å¯åŠ¨ vLLM æ¨ç†æœåŠ¡
bash scripts/vllm.sh
```

**ç­‰å¾…è¾“å‡ºï¼š**
```
INFO:     Started server process
INFO:     Uvicorn running on http://0.0.0.0:8000
```

**å¦‚æœé‡åˆ° OOM é”™è¯¯ï¼Œç¼–è¾‘ `scripts/vllm.sh`ï¼Œé™ä½æ˜¾å­˜ä½¿ç”¨ï¼š**
- å‡å° `--gpu-memory-utilization`ï¼ˆå¦‚ 0.8ï¼‰
- å‡å° `--max-num-seqs`ï¼ˆå¦‚ 64ï¼‰

### 6.2 éªŒè¯ vLLM æœåŠ¡

**æ‰“å¼€æ–°ç»ˆç«¯ï¼Œæ£€æŸ¥æœåŠ¡çŠ¶æ€ï¼š**

```bash
bash scripts/check_vllm.sh
# æˆ–æ‰‹åŠ¨æ£€æŸ¥
curl http://localhost:8000/health
```

---

## 7. å¯åŠ¨ API æœåŠ¡

### 7.1 å¯åŠ¨ FastAPI æœåŠ¡

**æ‰“å¼€ç»ˆç«¯ 2ï¼š**

```bash
# å¯åŠ¨ FastAPI RAG æœåŠ¡
bash scripts/fastapi.sh
```

**ç­‰å¾…è¾“å‡ºï¼š**
```
INFO:     Started server process
INFO:     Uvicorn running on http://0.0.0.0:8080
```

### 7.2 éªŒè¯ API æœåŠ¡

```bash
# æ£€æŸ¥å¥åº·çŠ¶æ€
curl http://localhost:8080/health

# æŸ¥çœ‹ç›‘æ§æŒ‡æ ‡
curl http://localhost:8080/metrics | jq
```

### 7.3 æµ‹è¯• APIï¼ˆå¯é€‰ï¼‰

```bash
# æµ‹è¯•èŠå¤©æ¥å£
curl -X POST http://localhost:8080/api/rag/chat \
    -H "Content-Type: application/json" \
    -d '{
        "query": "ä»€ä¹ˆæ˜¯åˆåŒè¿çº¦ï¼Ÿ",
        "temperature": 0.1,
        "max_tokens": 512,
        "stream": false
    }'
```

---

## 8. å¯åŠ¨å‰ç«¯ç•Œé¢

### 8.1 å¯åŠ¨ Streamlit å‰ç«¯

**æ‰“å¼€ç»ˆç«¯ 3ï¼š**

```bash
# å¯åŠ¨ Streamlit å‰ç«¯
bash scripts/frontend.sh
```

**ç­‰å¾…è¾“å‡ºï¼š**
```
You can now view your Streamlit app in your browser.
Local URL: http://localhost:8501
```

### 8.2 è®¿é—®å‰ç«¯

åœ¨æµè§ˆå™¨æ‰“å¼€ `http://localhost:8501`ï¼Œä½ å¯ä»¥ï¼š
- è¾“å…¥æ³•å¾‹é—®é¢˜
- æŸ¥çœ‹å®æ—¶æµå¼è¾“å‡º
- æŸ¥çœ‹ RAG æ£€ç´¢æ¥æº
- è°ƒæ•´æ¸©åº¦ã€æœ€å¤§ token æ•°ç­‰å‚æ•°

---

## 9. Docker éƒ¨ç½²

### 9.1 å®‰è£… Dockerï¼ˆå¦‚æœæœªå®‰è£…ï¼‰

**åœ¨ Autodl å®ä¾‹ä¸­ï¼š**

```bash
# å®‰è£… Docker
curl -fsSL https://get.docker.com | sh

# å®‰è£… NVIDIA Dockerï¼ˆGPU æ”¯æŒï¼‰
distribution=$(. /etc/os-release;echo $ID$VERSION_ID)
curl -s -L https://nvidia.github.io/nvidia-docker/gpgkey | sudo apt-key add -
curl -s -L https://nvidia.github.io/nvidia-docker/$distribution/nvidia-docker.list | \
    sudo tee /etc/apt/sources.list.d/nvidia-docker.list
sudo apt-get update
sudo apt-get install -y nvidia-docker2
sudo systemctl restart docker

# éªŒè¯ GPU æ”¯æŒ
docker run --rm --gpus all nvidia/cuda:12.1.0-base-ubuntu22.04 nvidia-smi
```

### 9.2 å‡†å¤‡æ¨¡å‹å’Œé…ç½®

**ç¡®ä¿ä»¥ä¸‹æ–‡ä»¶/ç›®å½•å­˜åœ¨ï¼š**
- `output/llama3-law-merged/` - åˆå¹¶åçš„æ¨¡å‹
- `chroma_db/` - å‘é‡æ•°æ®åº“ï¼ˆè‡³å°‘ä¸€ä¸ªï¼‰
- `config/` - é…ç½®æ–‡ä»¶

### 9.3 å¯åŠ¨ Docker æœåŠ¡

```bash
# ä¸€é”®å¯åŠ¨æ‰€æœ‰æœåŠ¡
bash scripts/docker-start.sh

# æˆ–æ‰‹åŠ¨å¯åŠ¨
docker-compose up -d --build
```

**ç­‰å¾…æœåŠ¡å¯åŠ¨ï¼ˆçº¦ 1-2 åˆ†é’Ÿï¼‰ï¼š**

```bash
# æŸ¥çœ‹æœåŠ¡çŠ¶æ€
docker-compose ps

# æŸ¥çœ‹æ—¥å¿—
docker-compose logs -f
```

### 9.4 éªŒè¯ Docker éƒ¨ç½²

```bash
# æ£€æŸ¥å®¹å™¨å¥åº·çŠ¶æ€
docker inspect legalflash-rag-vllm | grep -A 10 Health
docker inspect legalflash-rag-app | grep -A 10 Health

# æ£€æŸ¥æœåŠ¡ç«¯ç‚¹
curl http://localhost:8000/health  # vLLM
curl http://localhost:8080/health  # FastAPI
```

**è®¿é—®æœåŠ¡ï¼š**
- vLLM API: `http://localhost:8000`
- FastAPI: `http://localhost:8080`
- Streamlit: `http://localhost:8501`

### 9.5 åœæ­¢ Docker æœåŠ¡

```bash
# åœæ­¢æ‰€æœ‰æœåŠ¡
bash scripts/docker-stop.sh

# æˆ–æ‰‹åŠ¨åœæ­¢
docker-compose down
```

---

## 10. æ€§èƒ½å‹æµ‹

### 10.1 å®‰è£… Locustï¼ˆå¦‚æœæœªå®‰è£…ï¼‰

```bash
pip install locust
```

### 10.2 è¿è¡Œå‹æµ‹

**æ–¹å¼ 1ï¼šä½¿ç”¨è„šæœ¬ï¼ˆæ¨èï¼‰**

```bash
# ä½¿ç”¨é»˜è®¤é…ç½®è¿è¡Œå‹æµ‹
bash scripts/run_load_test.sh

# è‡ªå®šä¹‰å‚æ•°
HOST=http://localhost:8080 \
USERS=50 \
SPAWN_RATE=5 \
DURATION=5m \
bash scripts/run_load_test.sh
```

**æ–¹å¼ 2ï¼šä½¿ç”¨ Locust Web UI**

```bash
# å¯åŠ¨ Locust Web UI
locust -f tests/locustfile.py --host=http://localhost:8080

# ç„¶ååœ¨æµè§ˆå™¨æ‰“å¼€ http://localhost:8089
# è®¾ç½®å¹¶å‘ç”¨æˆ·æ•°ã€å¢é•¿é€Ÿç‡ç­‰å‚æ•°ï¼Œç‚¹å‡» "Start" å¼€å§‹å‹æµ‹
```

**æ–¹å¼ 3ï¼šæ— å¤´æ¨¡å¼ï¼ˆå‘½ä»¤è¡Œï¼‰**

```bash
locust -f tests/locustfile.py \
    --host=http://localhost:8080 \
    --users=50 \
    --spawn-rate=5 \
    --run-time=5m \
    --headless \
    --html=reports/locust_report.html \
    --csv=reports/locust_stats
```

### 10.3 æŸ¥çœ‹å‹æµ‹æŠ¥å‘Š

```bash
# HTML æŠ¥å‘Š
open reports/locust_report.html

# CSV ç»Ÿè®¡
cat reports/locust_stats_stats.csv
```

**å…³é”®æŒ‡æ ‡ï¼š**
- **RPS (Requests Per Second)**: æ¯ç§’è¯·æ±‚æ•°
- **å“åº”æ—¶é—´**: å¹³å‡å»¶è¿Ÿã€P50/P95/P99 å»¶è¿Ÿ
- **é”™è¯¯ç‡**: å¤±è´¥è¯·æ±‚ç™¾åˆ†æ¯”

### 10.4 ç›‘æ§ç³»ç»ŸæŒ‡æ ‡

**åœ¨å‹æµ‹è¿‡ç¨‹ä¸­ï¼Œå®æ—¶æŸ¥çœ‹ç›‘æ§æŒ‡æ ‡ï¼š**

```bash
# æŸ¥çœ‹å®Œæ•´ç›‘æ§æŒ‡æ ‡
curl http://localhost:8080/metrics | jq

# æŸ¥çœ‹ GPU ä½¿ç”¨æƒ…å†µ
watch -n 1 'curl -s http://localhost:8080/metrics | jq ".gpu"'
```

---

## ğŸ“Š å®Œæ•´æµç¨‹æ€»ç»“

```mermaid
graph TD
    A[1. ç¯å¢ƒå‡†å¤‡] --> B[2. æ•°æ®å‡†å¤‡]
    B --> C[3. æ¨¡å‹è®­ç»ƒ]
    C --> D[4. æƒé‡åˆå¹¶]
    D --> E[5. æ„å»º RAG çŸ¥è¯†åº“]
    E --> F[6. å¯åŠ¨ vLLM æœåŠ¡]
    F --> G[7. å¯åŠ¨ FastAPI æœåŠ¡]
    G --> H[8. å¯åŠ¨å‰ç«¯ç•Œé¢]
    H --> I[9. Docker éƒ¨ç½²]
    I --> J[10. æ€§èƒ½å‹æµ‹]
```

---

## âš ï¸ å¸¸è§é—®é¢˜

### Q1: è®­ç»ƒæ—¶æ˜¾å­˜ä¸è¶³ï¼Ÿ

**è§£å†³æ–¹æ¡ˆï¼š**
1. åœ¨ `config/train_config.yaml` ä¸­å¯ç”¨ 4-bit é‡åŒ–ï¼š`load_in_4bit: true`
2. å‡å°æ‰¹æ¬¡å¤§å°ï¼š`per_device_train_batch_size: 4`
3. å¢åŠ æ¢¯åº¦ç´¯ç§¯ï¼š`gradient_accumulation_steps: 2`

### Q2: vLLM å¯åŠ¨å¤±è´¥ï¼Œæç¤º OOMï¼Ÿ

**è§£å†³æ–¹æ¡ˆï¼š**
1. ç¼–è¾‘ `scripts/vllm.sh`ï¼Œé™ä½ `--gpu-memory-utilization`ï¼ˆå¦‚ 0.8ï¼‰
2. å‡å° `--max-num-seqs`ï¼ˆå¦‚ 64ï¼‰
3. å‡å° `--max-model-len`ï¼ˆå¦‚ 2048ï¼‰

### Q3: Docker å®¹å™¨æ— æ³•è®¿é—® GPUï¼Ÿ

**è§£å†³æ–¹æ¡ˆï¼š**
1. ç¡®ä¿å®‰è£…äº† NVIDIA Dockerï¼š`nvidia-docker2`
2. éªŒè¯ GPU æ”¯æŒï¼š`docker run --rm --gpus all nvidia/cuda:12.1.0-base-ubuntu22.04 nvidia-smi`
3. æ£€æŸ¥ `docker-compose.yml` ä¸­çš„ GPU é…ç½®

### Q4: å‹æµ‹æ—¶å“åº”æ—¶é—´è¿‡é•¿ï¼Ÿ

**è§£å†³æ–¹æ¡ˆï¼š**
1. æ£€æŸ¥ GPU ä½¿ç”¨ç‡ï¼š`curl http://localhost:8080/metrics | jq ".gpu"`
2. å¦‚æœ GPU åˆ©ç”¨ç‡ä½ï¼Œå¢åŠ  `--max-num-seqs`
3. å¦‚æœ GPU åˆ©ç”¨ç‡é«˜ï¼Œè€ƒè™‘å¢åŠ  GPU æ•°é‡æˆ–ä¼˜åŒ–æ¨¡å‹

---

## ğŸ“ å¿«é€Ÿå‘½ä»¤é€ŸæŸ¥

```bash
# æ•°æ®å‡†å¤‡
python scripts/prepare_dataset.py <input_file>

# è®­ç»ƒ
python train.py

# æƒé‡åˆå¹¶
python merge.py

# æ„å»ºçŸ¥è¯†åº“
python ingest.py --docs_path <file> --knowledge_type <type>

# å¯åŠ¨æœåŠ¡
bash scripts/vllm.sh        # ç»ˆç«¯ 1
bash scripts/fastapi.sh      # ç»ˆç«¯ 2
bash scripts/frontend.sh     # ç»ˆç«¯ 3

# Docker éƒ¨ç½²
bash scripts/docker-start.sh
bash scripts/docker-stop.sh

# å‹æµ‹
bash scripts/run_load_test.sh
```

---

## ğŸ‰ å®Œæˆï¼

æ­å–œï¼ä½ å·²ç»å®Œæˆäº†ä»æ¨¡å‹è®­ç»ƒåˆ°ç”Ÿäº§éƒ¨ç½²çš„å®Œæ•´æµç¨‹ã€‚

**ä¸‹ä¸€æ­¥ï¼š**
- æ ¹æ®ä¸šåŠ¡éœ€æ±‚è°ƒæ•´æ¨¡å‹å‚æ•°
- ä¼˜åŒ– RAG æ£€ç´¢ç­–ç•¥
- æ·»åŠ æ›´å¤šç›‘æ§æŒ‡æ ‡
- æ‰©å±•çŸ¥è¯†åº“å†…å®¹

**éœ€è¦å¸®åŠ©ï¼Ÿ**
- æŸ¥çœ‹ `README.md` è·å–æ›´å¤šä¿¡æ¯
- æŸ¥çœ‹ `docs/` ç›®å½•ä¸‹çš„è¯¦ç»†æ–‡æ¡£
- æ£€æŸ¥ `config/train_config.yaml` ä¸­çš„é…ç½®è¯´æ˜

