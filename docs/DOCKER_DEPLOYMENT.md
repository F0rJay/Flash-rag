# Docker éƒ¨ç½²æŒ‡å—

## ğŸ“‹ å‰ç½®è¦æ±‚

### 1. ç³»ç»Ÿè¦æ±‚

- **æ“ä½œç³»ç»Ÿ**: Linux (Ubuntu 20.04+ æ¨è)
- **GPU**: NVIDIA GPU (æ”¯æŒ CUDA 12.1+)
- **å†…å­˜**: è‡³å°‘ 32GB RAM
- **å­˜å‚¨**: è‡³å°‘ 100GB å¯ç”¨ç©ºé—´ï¼ˆç”¨äºæ¨¡å‹å’Œå‘é‡æ•°æ®åº“ï¼‰

### 2. è½¯ä»¶å®‰è£…

#### å®‰è£… Docker

```bash
# å®‰è£… Docker
curl -fsSL https://get.docker.com | sh
sudo usermod -aG docker $USER

# é‡æ–°ç™»å½•æˆ–æ‰§è¡Œ
newgrp docker

# éªŒè¯å®‰è£…
docker --version
```

#### å®‰è£… Docker Compose

```bash
# æ–¹æ³•1: ä½¿ç”¨ pip å®‰è£…
pip install docker-compose

# æ–¹æ³•2: ä½¿ç”¨å®˜æ–¹è„šæœ¬
sudo curl -L "https://github.com/docker/compose/releases/latest/download/docker-compose-$(uname -s)-$(uname -m)" -o /usr/local/bin/docker-compose
sudo chmod +x /usr/local/bin/docker-compose

# éªŒè¯å®‰è£…
docker-compose --version
```

#### å®‰è£… NVIDIA Dockerï¼ˆGPU æ”¯æŒï¼‰

```bash
# æ·»åŠ  NVIDIA Docker ä»“åº“
distribution=$(. /etc/os-release;echo $ID$VERSION_ID)
curl -s -L https://nvidia.github.io/nvidia-docker/gpgkey | sudo apt-key add -
curl -s -L https://nvidia.github.io/nvidia-docker/$distribution/nvidia-docker.list | \
    sudo tee /etc/apt/sources.list.d/nvidia-docker.list

# å®‰è£… NVIDIA Docker
sudo apt-get update
sudo apt-get install -y nvidia-docker2

# é‡å¯ Docker
sudo systemctl restart docker

# éªŒè¯ GPU æ”¯æŒ
docker run --rm --gpus all nvidia/cuda:12.1.0-base-ubuntu22.04 nvidia-smi
```

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. å‡†å¤‡æ¨¡å‹

ç¡®ä¿å·²å®Œæˆæ¨¡å‹è®­ç»ƒå’Œæƒé‡åˆå¹¶ï¼š

```bash
# æ£€æŸ¥æ¨¡å‹æ˜¯å¦å­˜åœ¨
ls -lh output/llama3-law-merged/
```

å¦‚æœæ¨¡å‹ä¸å­˜åœ¨ï¼Œè¯·å…ˆå®Œæˆï¼š
1. æ¨¡å‹è®­ç»ƒï¼š`python src/training/train.py`
2. æƒé‡åˆå¹¶ï¼š`python src/training/merge.py`

### 2. å‡†å¤‡çŸ¥è¯†åº“ï¼ˆå¯é€‰ï¼‰

å¦‚æœå·²æœ‰å‘é‡æ•°æ®åº“ï¼Œç¡®ä¿åœ¨ä»¥ä¸‹ç›®å½•ï¼š
- `chroma_db/` - æ³•æ¡å‹çŸ¥è¯†åº“
- `chroma_db_case/` - æ¡ˆä¾‹å‹çŸ¥è¯†åº“
- `chroma_db_judgement/` - åˆ¤å†³ä¹¦å‹çŸ¥è¯†åº“

å¦‚æœæ²¡æœ‰ï¼Œå¯ä»¥ç¨åæ„å»ºã€‚

### 3. å¯åŠ¨æœåŠ¡

```bash
# ä½¿ç”¨å¯åŠ¨è„šæœ¬ï¼ˆæ¨èï¼‰
bash scripts/docker-start.sh

# æˆ–æ‰‹åŠ¨å¯åŠ¨
docker-compose up -d
```

### 4. éªŒè¯æœåŠ¡

```bash
# æ£€æŸ¥æœåŠ¡çŠ¶æ€
docker-compose ps

# æ£€æŸ¥ vLLM æœåŠ¡
curl http://localhost:8000/health

# æ£€æŸ¥ FastAPI æœåŠ¡
curl http://localhost:8080/health

# è®¿é—®å‰ç«¯
# æµè§ˆå™¨æ‰“å¼€: http://localhost:8501
```

## ğŸ“Š æœåŠ¡æ¶æ„

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Docker Compose Network          â”‚
â”‚                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ vllm-service â”‚    â”‚ app-service  â”‚  â”‚
â”‚  â”‚              â”‚    â”‚              â”‚  â”‚
â”‚  â”‚ Port: 8000   â”‚â—„â”€â”€â”€â”¤ FastAPI:8080 â”‚  â”‚
â”‚  â”‚ GPU: 1x      â”‚    â”‚ Streamlit:   â”‚  â”‚
â”‚  â”‚              â”‚    â”‚   8501       â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## âš™ï¸ é…ç½®è¯´æ˜

### ç¯å¢ƒå˜é‡

**vLLM æœåŠ¡ï¼š**
- `MODEL_PATH`: æ¨¡å‹è·¯å¾„ï¼ˆé»˜è®¤: `/app/models/llama3-law-merged`ï¼‰
- `HOST`: æœåŠ¡åœ°å€ï¼ˆé»˜è®¤: `0.0.0.0`ï¼‰
- `PORT`: æœåŠ¡ç«¯å£ï¼ˆé»˜è®¤: `8000`ï¼‰
- `DTYPE`: æ•°æ®ç±»å‹ï¼ˆé»˜è®¤: `bfloat16`ï¼‰
- `GPU_MEMORY_UTILIZATION`: æ˜¾å­˜ä½¿ç”¨ç‡ï¼ˆé»˜è®¤: `0.85`ï¼‰
- `MAX_MODEL_LEN`: æœ€å¤§åºåˆ—é•¿åº¦ï¼ˆé»˜è®¤: `4096`ï¼‰
- `MAX_NUM_SEQS`: æœ€å¤§å¹¶å‘åºåˆ—æ•°ï¼ˆé»˜è®¤: `128`ï¼‰

**App æœåŠ¡ï¼š**
- `VLLM_URL`: vLLM æœåŠ¡åœ°å€ï¼ˆé»˜è®¤: `http://vllm-service:8000`ï¼‰
- `HF_ENDPOINT`: HuggingFace é•œåƒï¼ˆé»˜è®¤: `https://hf-mirror.com`ï¼‰

### è‡ªå®šä¹‰é…ç½®

å¤åˆ¶ `docker-compose.override.yml.example` ä¸º `docker-compose.override.yml`ï¼š

```bash
cp docker-compose.override.yml.example docker-compose.override.yml
```

ç„¶åç¼–è¾‘ `docker-compose.override.yml` æ¥è‡ªå®šä¹‰é…ç½®ã€‚

## ğŸ”§ å¸¸ç”¨æ“ä½œ

### æŸ¥çœ‹æ—¥å¿—

```bash
# æŸ¥çœ‹æ‰€æœ‰æœåŠ¡æ—¥å¿—
docker-compose logs -f

# æŸ¥çœ‹ç‰¹å®šæœåŠ¡æ—¥å¿—
docker-compose logs -f vllm-service
docker-compose logs -f app-service
```

### é‡å¯æœåŠ¡

```bash
# é‡å¯æ‰€æœ‰æœåŠ¡
docker-compose restart

# é‡å¯ç‰¹å®šæœåŠ¡
docker-compose restart vllm-service
docker-compose restart app-service
```

### åœæ­¢æœåŠ¡

```bash
# åœæ­¢æœåŠ¡ï¼ˆä¿ç•™å®¹å™¨ï¼‰
docker-compose stop

# åœæ­¢å¹¶åˆ é™¤å®¹å™¨
docker-compose down

# åœæ­¢å¹¶åˆ é™¤å®¹å™¨å’Œå·
docker-compose down -v
```

### æ›´æ–°æœåŠ¡

```bash
# é‡æ–°æ„å»ºé•œåƒ
docker-compose build

# é‡æ–°æ„å»ºå¹¶å¯åŠ¨
docker-compose up -d --build
```

## ğŸ› æ•…éšœæ’æŸ¥

### é—®é¢˜ 1: GPU ä¸å¯ç”¨

**ç—‡çŠ¶ï¼š** vLLM æœåŠ¡å¯åŠ¨å¤±è´¥ï¼Œæç¤º GPU ç›¸å…³é”™è¯¯

**è§£å†³ï¼š**
```bash
# æ£€æŸ¥ NVIDIA Docker æ˜¯å¦æ­£ç¡®å®‰è£…
docker run --rm --gpus all nvidia/cuda:12.1.0-base-ubuntu22.04 nvidia-smi

# å¦‚æœå¤±è´¥ï¼Œé‡æ–°å®‰è£… NVIDIA Docker
sudo apt-get install -y nvidia-docker2
sudo systemctl restart docker
```

### é—®é¢˜ 2: æ¨¡å‹è·¯å¾„ä¸å­˜åœ¨

**ç—‡çŠ¶ï¼š** vLLM æœåŠ¡å¯åŠ¨å¤±è´¥ï¼Œæç¤ºæ¨¡å‹è·¯å¾„ä¸å­˜åœ¨

**è§£å†³ï¼š**
1. æ£€æŸ¥æ¨¡å‹æ˜¯å¦å·²è®­ç»ƒå’Œåˆå¹¶
2. ä¿®æ”¹ `docker-compose.yml` ä¸­çš„ `MODEL_PATH` ç¯å¢ƒå˜é‡
3. ç¡®ä¿ volume æŒ‚è½½è·¯å¾„æ­£ç¡®

### é—®é¢˜ 3: ç«¯å£å†²çª

**ç—‡çŠ¶ï¼š** æœåŠ¡å¯åŠ¨å¤±è´¥ï¼Œæç¤ºç«¯å£å·²è¢«å ç”¨

**è§£å†³ï¼š**
```bash
# æ£€æŸ¥ç«¯å£å ç”¨
sudo lsof -i :8000
sudo lsof -i :8080
sudo lsof -i :8501

# ä¿®æ”¹ docker-compose.yml ä¸­çš„ç«¯å£æ˜ å°„
ports:
  - "8001:8000"  # æ”¹ä¸ºå…¶ä»–ç«¯å£
```

### é—®é¢˜ 4: å®¹å™¨æ— æ³•è¿æ¥

**ç—‡çŠ¶ï¼š** App æœåŠ¡æ— æ³•è¿æ¥åˆ° vLLM æœåŠ¡

**è§£å†³ï¼š**
1. æ£€æŸ¥æœåŠ¡æ˜¯å¦åœ¨åŒä¸€ç½‘ç»œï¼š`docker network ls`
2. æ£€æŸ¥ vLLM æœåŠ¡å¥åº·çŠ¶æ€ï¼š`curl http://localhost:8000/health`
3. æ£€æŸ¥ç¯å¢ƒå˜é‡ `VLLM_URL` æ˜¯å¦æ­£ç¡®

## ğŸ“ˆ æ€§èƒ½ä¼˜åŒ–

### GPU èµ„æºä¼˜åŒ–

```yaml
# docker-compose.override.yml
services:
  vllm-service:
    environment:
      - GPU_MEMORY_UTILIZATION=0.9  # æé«˜æ˜¾å­˜ä½¿ç”¨ç‡
      - MAX_NUM_SEQS=256  # å¢åŠ å¹¶å‘æ•°
```

### å†…å­˜ä¼˜åŒ–

```yaml
services:
  app-service:
    deploy:
      resources:
        limits:
          memory: 8G
        reservations:
          memory: 4G
```

## ğŸ”’ ç”Ÿäº§ç¯å¢ƒå»ºè®®

1. **ä½¿ç”¨ç¯å¢ƒå˜é‡æ–‡ä»¶**: åˆ›å»º `.env` æ–‡ä»¶å­˜å‚¨æ•æ„Ÿé…ç½®
2. **å¯ç”¨ HTTPS**: ä½¿ç”¨ Nginx åå‘ä»£ç†ï¼Œé…ç½® SSL è¯ä¹¦
3. **æ—¥å¿—ç®¡ç†**: é…ç½®æ—¥å¿—è½®è½¬å’Œé›†ä¸­æ—¥å¿—ç®¡ç†
4. **ç›‘æ§å‘Šè­¦**: é›†æˆ Prometheus + Grafana ç›‘æ§
5. **å¤‡ä»½ç­–ç•¥**: å®šæœŸå¤‡ä»½æ¨¡å‹å’Œå‘é‡æ•°æ®åº“
6. **èµ„æºé™åˆ¶**: è®¾ç½®åˆç†çš„ CPU å’Œå†…å­˜é™åˆ¶

## ğŸ“š å‚è€ƒèµ„æº

- [Docker å®˜æ–¹æ–‡æ¡£](https://docs.docker.com/)
- [Docker Compose æ–‡æ¡£](https://docs.docker.com/compose/)
- [NVIDIA Docker æ–‡æ¡£](https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/)
- [vLLM æ–‡æ¡£](https://docs.vllm.ai/)

