#!/usr/bin/env python3
"""
RAG çŸ¥è¯†åº“å‡†å¤‡è„šæœ¬
åŠŸèƒ½ï¼š
1. ä» DISC-Law JSONL æ–‡ä»¶ä¸­æå–å†…å®¹
   - æ¨¡å¼1: æå–æ³•å¾‹æ¡æ–‡ï¼ˆreference å­—æ®µï¼‰- æ³•æ¡å‹ RAG
   - æ¨¡å¼2: æå–æ¡ˆä¾‹ï¼ˆinput + outputï¼‰- æ¡ˆä¾‹å‹ RAG
   - æ¨¡å¼3: æå–åˆ¤å†³ä¹¦ï¼ˆinput å­—æ®µï¼‰- åˆ¤å†³ä¹¦å‹ RAG
   - æ¨¡å¼4: æå–æ³•æ¡+æ¡ˆä¾‹ï¼ˆæ··åˆæ¨¡å¼ï¼‰
2. å»é‡å¹¶åˆå¹¶
3. ä¿å­˜ä¸ºæ–‡æœ¬æ–‡ä»¶ä¾› ingest.py ä½¿ç”¨

ä½¿ç”¨æ–¹æ³•ï¼š
    # æå–æ³•å¾‹æ¡æ–‡ï¼ˆæ³•æ¡å‹ RAGï¼‰
    python scripts/prepare_rag_knowledge.py <file1.jsonl> --mode law --output data/docs/legal_docs.txt
    
    # æå–æ¡ˆä¾‹ï¼ˆæ¡ˆä¾‹å‹ RAGï¼‰
    python scripts/prepare_rag_knowledge.py <file1.jsonl> --mode case --output data/docs/case_docs.txt
    
    # æå–åˆ¤å†³ä¹¦ï¼ˆåˆ¤å†³ä¹¦å‹ RAGï¼‰
    python scripts/prepare_rag_knowledge.py <file1.jsonl> --mode judgement --output data/docs/judgement_docs.txt
    
    # æ··åˆæ¨¡å¼ï¼ˆæ³•æ¡+æ¡ˆä¾‹ï¼‰
    python scripts/prepare_rag_knowledge.py <file1.jsonl> --mode mixed --output data/docs/mixed_docs.txt
"""

import json
import argparse
from pathlib import Path
from typing import Set, List

def extract_references_from_jsonl(file_path: Path) -> Set[str]:
    """ä» JSONL æ–‡ä»¶ä¸­æå–æ‰€æœ‰ reference å­—æ®µçš„å†…å®¹ï¼ˆæ³•æ¡ï¼‰"""
    references = set()
    
    print(f"ğŸ“‚ å¤„ç†æ–‡ä»¶: {file_path}")
    with open(file_path, 'r', encoding='utf-8') as f:
        count = 0
        for line_num, line in enumerate(f, 1):
            if not line.strip():
                continue
            try:
                item = json.loads(line)
                # æå– reference å­—æ®µï¼ˆå¯èƒ½æ˜¯åˆ—è¡¨ï¼‰
                if 'reference' in item:
                    refs = item['reference']
                    if isinstance(refs, list):
                        for ref in refs:
                            if ref and ref.strip():
                                references.add(ref.strip())
                    elif isinstance(refs, str) and refs.strip():
                        references.add(refs.strip())
                count += 1
            except json.JSONDecodeError as e:
                print(f"âš ï¸  è­¦å‘Š: ç¬¬ {line_num} è¡Œ JSON è§£æå¤±è´¥: {e}")
                continue
    
    print(f"âœ… ä» {count} æ¡è®°å½•ä¸­æå–äº† {len(references)} æ¡å”¯ä¸€æ³•å¾‹æ¡æ–‡")
    return references

def extract_cases_from_jsonl(file_path: Path) -> List[str]:
    """ä» JSONL æ–‡ä»¶ä¸­æå–æ¡ˆä¾‹ï¼ˆinput + outputï¼‰"""
    cases = []
    
    print(f"ğŸ“‚ å¤„ç†æ–‡ä»¶: {file_path}")
    with open(file_path, 'r', encoding='utf-8') as f:
        count = 0
        for line_num, line in enumerate(f, 1):
            if not line.strip():
                continue
            try:
                item = json.loads(line)
                # æå–æ¡ˆä¾‹ï¼šæ¡ˆä»¶æè¿° + åˆ¤å†³ç»“æœ
                input_text = item.get('input', '').strip()
                output_text = item.get('output', '').strip()
                
                if input_text and output_text:
                    # æ ¼å¼åŒ–æ¡ˆä¾‹æ–‡æœ¬
                    case_text = f"ã€æ¡ˆä»¶äº‹å®ã€‘\n{input_text}\n\nã€åˆ¤å†³ç»“æœã€‘\n{output_text}"
                    cases.append(case_text)
                count += 1
            except json.JSONDecodeError as e:
                print(f"âš ï¸  è­¦å‘Š: ç¬¬ {line_num} è¡Œ JSON è§£æå¤±è´¥: {e}")
                continue
    
    print(f"âœ… ä» {count} æ¡è®°å½•ä¸­æå–äº† {len(cases)} ä¸ªæ¡ˆä¾‹")
    return cases

def extract_judgements_from_jsonl(file_path: Path) -> List[str]:
    """ä» JSONL æ–‡ä»¶ä¸­æå–åˆ¤å†³ä¹¦ï¼ˆinput å­—æ®µï¼ŒåŒ…å«å®Œæ•´åˆ¤å†³ä¹¦åŸæ–‡ï¼‰"""
    judgements = []
    
    print(f"ğŸ“‚ å¤„ç†æ–‡ä»¶: {file_path}")
    with open(file_path, 'r', encoding='utf-8') as f:
        count = 0
        for line_num, line in enumerate(f, 1):
            if not line.strip():
                continue
            try:
                item = json.loads(line)
                # æå–åˆ¤å†³ä¹¦ï¼šå®Œæ•´çš„åˆ¤å†³ä¹¦åŸæ–‡ï¼ˆinput å­—æ®µï¼‰
                input_text = item.get('input', '').strip()
                output_text = item.get('output', '').strip()  # æ‘˜è¦ï¼Œå¯é€‰
                
                if input_text:
                    # å¦‚æœ input åŒ…å«"è¯·å¤§è‡´æè¿°"ç­‰æç¤ºè¯ï¼Œå»é™¤
                    if input_text.startswith("è¯·å¤§è‡´æè¿°") or input_text.startswith("è¿™æ˜¯ä¸€ç¯‡æ³•å¾‹æ–‡ä¹¦"):
                        # æ‰¾åˆ°ç¬¬ä¸€ä¸ªæ¢è¡Œåçš„å†…å®¹
                        lines = input_text.split('\n', 1)
                        if len(lines) > 1:
                            input_text = lines[1].strip()
                    
                    # æ ¼å¼åŒ–åˆ¤å†³ä¹¦æ–‡æœ¬ï¼ˆåŒ…å«æ‘˜è¦ï¼‰
                    if output_text:
                        judgement_text = f"ã€åˆ¤å†³ä¹¦æ‘˜è¦ã€‘\n{output_text}\n\nã€åˆ¤å†³ä¹¦å…¨æ–‡ã€‘\n{input_text}"
                    else:
                        judgement_text = f"ã€åˆ¤å†³ä¹¦å…¨æ–‡ã€‘\n{input_text}"
                    judgements.append(judgement_text)
                count += 1
            except json.JSONDecodeError as e:
                print(f"âš ï¸  è­¦å‘Š: ç¬¬ {line_num} è¡Œ JSON è§£æå¤±è´¥: {e}")
                continue
    
    print(f"âœ… ä» {count} æ¡è®°å½•ä¸­æå–äº† {len(judgements)} ä»½åˆ¤å†³ä¹¦")
    return judgements

def merge_references(file_paths: List[Path]) -> List[str]:
    """åˆå¹¶å¤šä¸ªæ–‡ä»¶ä¸­çš„æ³•å¾‹æ¡æ–‡å¹¶å»é‡"""
    all_references = set()
    
    for file_path in file_paths:
        if not file_path.exists():
            print(f"âŒ é”™è¯¯: æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
            continue
        
        refs = extract_references_from_jsonl(file_path)
        all_references.update(refs)
    
    # è½¬æ¢ä¸ºåˆ—è¡¨å¹¶æ’åºï¼ˆä¾¿äºé˜…è¯»ï¼‰
    sorted_references = sorted(list(all_references))
    return sorted_references

def merge_cases(file_paths: List[Path]) -> List[str]:
    """åˆå¹¶å¤šä¸ªæ–‡ä»¶ä¸­çš„æ¡ˆä¾‹"""
    all_cases = []
    
    for file_path in file_paths:
        if not file_path.exists():
            print(f"âŒ é”™è¯¯: æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
            continue
        
        cases = extract_cases_from_jsonl(file_path)
        all_cases.extend(cases)
    
    return all_cases

def extract_mixed(file_paths: List[Path]) -> List[str]:
    """æ··åˆæ¨¡å¼ï¼šæå–æ³•æ¡å’Œæ¡ˆä¾‹"""
    mixed_content = []
    
    # æå–æ³•æ¡
    references = merge_references(file_paths)
    mixed_content.extend([f"ã€æ³•å¾‹æ¡æ–‡ã€‘\n{ref}" for ref in references])
    
    # æå–æ¡ˆä¾‹
    cases = merge_cases(file_paths)
    mixed_content.extend(cases)
    
    return mixed_content

def merge_judgements(file_paths: List[Path]) -> List[str]:
    """åˆå¹¶å¤šä¸ªæ–‡ä»¶ä¸­çš„åˆ¤å†³ä¹¦"""
    all_judgements = []
    
    for file_path in file_paths:
        if not file_path.exists():
            print(f"âŒ é”™è¯¯: æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
            continue
        
        judgements = extract_judgements_from_jsonl(file_path)
        all_judgements.extend(judgements)
    
    return all_judgements

def save_to_text(content: List[str], output_path: Path, content_type: str = "æ³•å¾‹æ¡æ–‡"):
    """ä¿å­˜å†…å®¹åˆ°æ–‡æœ¬æ–‡ä»¶"""
    output_path.parent.mkdir(parents=True, exist_ok=True)
    
    with open(output_path, 'w', encoding='utf-8') as f:
        for item in content:
            f.write(item + '\n\n')  # æ¯ä¸ªæ¡ç›®ä¹‹é—´ç©ºä¸¤è¡Œ
    
    print(f"ğŸ’¾ å·²ä¿å­˜ {len(content)} æ¡{content_type}åˆ°: {output_path}")

def main():
    parser = argparse.ArgumentParser(description='å‡†å¤‡ RAG çŸ¥è¯†åº“ï¼ˆä» JSONL æå–å†…å®¹ï¼‰')
    parser.add_argument('files', nargs='+', type=str, help='è¾“å…¥çš„ JSONL æ–‡ä»¶è·¯å¾„ï¼ˆå¯å¤šä¸ªï¼‰')
    parser.add_argument('--mode', type=str, choices=['law', 'case', 'judgement', 'mixed'], default='law',
                       help='æå–æ¨¡å¼: law=æ³•å¾‹æ¡æ–‡, case=æ¡ˆä¾‹, judgement=åˆ¤å†³ä¹¦, mixed=æ··åˆï¼ˆé»˜è®¤: lawï¼‰')
    parser.add_argument('--output', type=str, default=None,
                       help='è¾“å‡ºæ–‡ä»¶è·¯å¾„ï¼ˆé»˜è®¤æ ¹æ®æ¨¡å¼è‡ªåŠ¨ç”Ÿæˆï¼‰')
    
    args = parser.parse_args()
    
    # è·å–é¡¹ç›®æ ¹ç›®å½•
    script_dir = Path(__file__).parent
    project_root = script_dir.parent
    
    # å¤„ç†è¾“å…¥æ–‡ä»¶è·¯å¾„
    input_files = []
    for file_path in args.files:
        file_path = Path(file_path)
        if not file_path.is_absolute():
            # å°è¯•ç›¸å¯¹äºé¡¹ç›®æ ¹ç›®å½•çš„çˆ¶ç›®å½•
            if (project_root.parent / file_path).exists():
                file_path = project_root.parent / file_path
            elif (project_root / file_path).exists():
                file_path = project_root / file_path
            else:
                file_path = Path(file_path).resolve()
        input_files.append(file_path)
    
    # å¤„ç†è¾“å‡ºæ–‡ä»¶è·¯å¾„
    if args.output is None:
        # æ ¹æ®æ¨¡å¼è‡ªåŠ¨ç”Ÿæˆè¾“å‡ºè·¯å¾„
        mode_map = {
            'law': 'data/docs/legal_docs.txt',
            'case': 'data/docs/case_docs.txt',
            'judgement': 'data/docs/judgement_docs.txt',
            'mixed': 'data/docs/mixed_docs.txt'
        }
        output_path = project_root / mode_map[args.mode]
    else:
        output_path = Path(args.output)
        if not output_path.is_absolute():
            output_path = project_root / output_path
    
    print("=" * 60)
    print("ğŸ“š RAG çŸ¥è¯†åº“å‡†å¤‡å·¥å…·")
    print("=" * 60)
    print(f"æ¨¡å¼: {args.mode}")
    print()
    
    # æ ¹æ®æ¨¡å¼æå–å†…å®¹
    if args.mode == 'law':
        content = merge_references(input_files)
        content_type = "æ³•å¾‹æ¡æ–‡"
    elif args.mode == 'case':
        content = merge_cases(input_files)
        content_type = "æ¡ˆä¾‹"
    elif args.mode == 'judgement':
        content = merge_judgements(input_files)
        content_type = "åˆ¤å†³ä¹¦"
    else:  # mixed
        content = extract_mixed(input_files)
        content_type = "æ··åˆå†…å®¹ï¼ˆæ³•æ¡+æ¡ˆä¾‹ï¼‰"
    
    if not content:
        print(f"âŒ é”™è¯¯: æœªèƒ½æå–åˆ°ä»»ä½•{content_type}")
        return
    
    # ä¿å­˜åˆ°æ–‡ä»¶
    save_to_text(content, output_path, content_type)
    
    # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
    print()
    print("=" * 60)
    print("ğŸ“Š ç»Ÿè®¡ä¿¡æ¯")
    print("=" * 60)
    print(f"è¾“å…¥æ–‡ä»¶æ•°: {len(input_files)}")
    print(f"æå–çš„{content_type}æ•°: {len(content)}")
    print(f"è¾“å‡ºæ–‡ä»¶: {output_path}")
    if output_path.exists():
        print(f"æ–‡ä»¶å¤§å°: {output_path.stat().st_size / 1024 / 1024:.2f} MB")
    print()
    print("ğŸ“ ç¤ºä¾‹ï¼ˆå‰ 2 æ¡ï¼‰:")
    for i, item in enumerate(content[:2], 1):
        preview = item[:150] + "..." if len(item) > 150 else item
        print(f"\n{i}. {preview}")

if __name__ == "__main__":
    main()

