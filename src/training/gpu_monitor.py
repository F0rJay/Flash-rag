#!/usr/bin/env python3
"""
GPU ç›‘æ§å›è°ƒç±»
åŠŸèƒ½ï¼š
1. å®æ—¶ç›‘æ§ GPU ä½¿ç”¨ç‡ã€æ˜¾å­˜ä½¿ç”¨ã€æ¸©åº¦ç­‰æŒ‡æ ‡
2. å°†æŒ‡æ ‡è®°å½•åˆ° TensorBoard
3. å®šæœŸæ‰“å° GPU çŠ¶æ€
"""

import torch
import time
from transformers import TrainerCallback
from typing import Optional

try:
    import pynvml
    PYNVML_AVAILABLE = True
except ImportError:
    PYNVML_AVAILABLE = False
    print("âš ï¸  è­¦å‘Š: pynvml æœªå®‰è£…ï¼Œå°†ä½¿ç”¨åŸºç¡€ GPU ç›‘æ§ï¼ˆä»…æ˜¾å­˜ï¼‰")
    print("   å®‰è£… pynvml ä»¥è·å¾—å®Œæ•´ç›‘æ§: pip install nvidia-ml-py3")


class GPUMonitorCallback(TrainerCallback):
    """GPU ç›‘æ§å›è°ƒç±»"""
    
    def __init__(self, log_interval: int = 10, enable_tensorboard: bool = True):
        """
        åˆå§‹åŒ– GPU ç›‘æ§å›è°ƒ
        
        Args:
            log_interval: æ‰“å° GPU çŠ¶æ€çš„é—´éš”ï¼ˆæ­¥æ•°ï¼‰
            enable_tensorboard: æ˜¯å¦å°†æŒ‡æ ‡è®°å½•åˆ° TensorBoard
        """
        self.log_interval = log_interval
        self.enable_tensorboard = enable_tensorboard
        self.step_count = 0
        self.writer = None
        
        # ä½¿ç”¨å®ä¾‹å˜é‡è·Ÿè¸ª NVML æ˜¯å¦å¯ç”¨
        self.pynvml_available = PYNVML_AVAILABLE
        self.handles = []
        
        # åˆå§‹åŒ– NVMLï¼ˆå¦‚æœå¯ç”¨ï¼‰
        if self.pynvml_available:
            try:
                pynvml.nvmlInit()
                self.device_count = pynvml.nvmlDeviceGetCount()
                self.handles = [pynvml.nvmlDeviceGetHandleByIndex(i) for i in range(self.device_count)]
                print(f"âœ… GPU ç›‘æ§å·²åˆå§‹åŒ–ï¼Œæ£€æµ‹åˆ° {self.device_count} ä¸ª GPU")
            except Exception as e:
                print(f"âš ï¸  NVML åˆå§‹åŒ–å¤±è´¥: {e}ï¼Œå°†ä½¿ç”¨åŸºç¡€ç›‘æ§")
                self.pynvml_available = False
                self.device_count = torch.cuda.device_count() if torch.cuda.is_available() else 0
                print(f"âœ… GPU ç›‘æ§å·²åˆå§‹åŒ–ï¼ˆåŸºç¡€æ¨¡å¼ï¼‰ï¼Œæ£€æµ‹åˆ° {self.device_count} ä¸ª GPU")
        else:
            self.device_count = torch.cuda.device_count() if torch.cuda.is_available() else 0
            print(f"âœ… GPU ç›‘æ§å·²åˆå§‹åŒ–ï¼ˆåŸºç¡€æ¨¡å¼ï¼‰ï¼Œæ£€æµ‹åˆ° {self.device_count} ä¸ª GPU")
    
    def on_train_begin(self, args, state, control, model=None, **kwargs):
        """è®­ç»ƒå¼€å§‹æ—¶åˆå§‹åŒ– TensorBoard writer"""
        if self.enable_tensorboard and hasattr(args, 'logging_dir'):
            try:
                from torch.utils.tensorboard import SummaryWriter
                self.writer = SummaryWriter(log_dir=args.logging_dir)
                print(f"ğŸ“Š GPU ç›‘æ§æŒ‡æ ‡å°†è®°å½•åˆ° TensorBoard: {args.logging_dir}")
            except ImportError:
                print("âš ï¸  TensorBoard æœªå®‰è£…ï¼ŒGPU æŒ‡æ ‡å°†ä¸ä¼šè®°å½•åˆ° TensorBoard")
                self.enable_tensorboard = False
    
    def on_log(self, args, state, control, logs=None, model=None, **kwargs):
        """æ¯æ¬¡æ—¥å¿—è®°å½•æ—¶ç›‘æ§ GPU"""
        if logs is None:
            return
        
        self.step_count = state.global_step
        
        # è·å– GPU æŒ‡æ ‡
        gpu_metrics = self._get_gpu_metrics()
        
        # è®°å½•åˆ° TensorBoard
        if self.enable_tensorboard and self.writer is not None:
            for gpu_id, metrics in gpu_metrics.items():
                for metric_name, value in metrics.items():
                    if value is not None:
                        self.writer.add_scalar(
                            f'gpu/{gpu_id}/{metric_name}',
                            value,
                            self.step_count
                        )
        
        # å®šæœŸæ‰“å° GPU çŠ¶æ€
        if self.step_count % self.log_interval == 0:
            self._print_gpu_status(gpu_metrics)
    
    def on_train_end(self, args, state, control, model=None, **kwargs):
        """è®­ç»ƒç»“æŸæ—¶å…³é—­ TensorBoard writer"""
        if self.writer is not None:
            self.writer.close()
        
        if self.pynvml_available:
            try:
                pynvml.nvmlShutdown()
            except:
                pass
    
    def _get_gpu_metrics(self) -> dict:
        """è·å–æ‰€æœ‰ GPU çš„æŒ‡æ ‡"""
        gpu_metrics = {}
        
        if not torch.cuda.is_available():
            return gpu_metrics
        
        for gpu_id in range(self.device_count):
            metrics = {}
            
            # åŸºç¡€æŒ‡æ ‡ï¼ˆä½¿ç”¨ PyTorchï¼‰
            if torch.cuda.is_available():
                torch.cuda.set_device(gpu_id)
                # æ˜¾å­˜ä½¿ç”¨ï¼ˆMBï¼‰
                memory_allocated = torch.cuda.memory_allocated(gpu_id) / 1024**2
                memory_reserved = torch.cuda.memory_reserved(gpu_id) / 1024**2
                memory_total = torch.cuda.get_device_properties(gpu_id).total_memory / 1024**2
                
                metrics['memory_allocated_mb'] = memory_allocated
                metrics['memory_reserved_mb'] = memory_reserved
                metrics['memory_total_mb'] = memory_total
                metrics['memory_usage_percent'] = (memory_allocated / memory_total * 100) if memory_total > 0 else 0
                metrics['memory_reserved_percent'] = (memory_reserved / memory_total * 100) if memory_total > 0 else 0
            
            # é«˜çº§æŒ‡æ ‡ï¼ˆä½¿ç”¨ NVMLï¼Œå¦‚æœå¯ç”¨ï¼‰
            if self.pynvml_available and gpu_id < len(self.handles):
                try:
                    handle = self.handles[gpu_id]
                    
                    # GPU ä½¿ç”¨ç‡
                    util = pynvml.nvmlDeviceGetUtilizationRates(handle)
                    metrics['utilization_gpu_percent'] = util.gpu
                    metrics['utilization_memory_percent'] = util.memory
                    
                    # æ¸©åº¦
                    try:
                        temp = pynvml.nvmlDeviceGetTemperature(handle, pynvml.NVML_TEMPERATURE_GPU)
                        metrics['temperature_celsius'] = temp
                    except:
                        metrics['temperature_celsius'] = None
                    
                    # åŠŸè€—
                    try:
                        power = pynvml.nvmlDeviceGetPowerUsage(handle) / 1000.0  # è½¬æ¢ä¸ºç“¦ç‰¹
                        power_limit = pynvml.nvmlDeviceGetPowerManagementLimitConstraints(handle)[1] / 1000.0
                        metrics['power_usage_watts'] = power
                        metrics['power_limit_watts'] = power_limit
                        metrics['power_usage_percent'] = (power / power_limit * 100) if power_limit > 0 else None
                    except:
                        metrics['power_usage_watts'] = None
                        metrics['power_limit_watts'] = None
                        metrics['power_usage_percent'] = None
                    
                    # æ˜¾å­˜ä¿¡æ¯ï¼ˆNVML ç‰ˆæœ¬ï¼Œæ›´å‡†ç¡®ï¼‰
                    try:
                        mem_info = pynvml.nvmlDeviceGetMemoryInfo(handle)
                        metrics['memory_used_mb_nvml'] = mem_info.used / 1024**2
                        metrics['memory_free_mb_nvml'] = mem_info.free / 1024**2
                        metrics['memory_total_mb_nvml'] = mem_info.total / 1024**2
                    except:
                        pass
                    
                except Exception as e:
                    # NVML æŸ¥è¯¢å¤±è´¥ï¼Œä½¿ç”¨åŸºç¡€æŒ‡æ ‡
                    pass
            
            gpu_metrics[f'gpu_{gpu_id}'] = metrics
        
        return gpu_metrics
    
    def _print_gpu_status(self, gpu_metrics: dict):
        """æ‰“å° GPU çŠ¶æ€"""
        if not gpu_metrics:
            return
        
        print("\n" + "="*60)
        print(f"ğŸ“Š GPU çŠ¶æ€ (Step {self.step_count})")
        print("="*60)
        
        for gpu_id, metrics in gpu_metrics.items():
            print(f"\n{gpu_id.upper()}:")
            
            # æ˜¾å­˜ä¿¡æ¯
            if 'memory_allocated_mb' in metrics:
                allocated = metrics['memory_allocated_mb']
                reserved = metrics['memory_reserved_mb']
                total = metrics['memory_total_mb']
                usage_pct = metrics.get('memory_usage_percent', 0)
                
                print(f"  æ˜¾å­˜: {allocated:.1f}MB / {total:.1f}MB ({usage_pct:.1f}%)")
                print(f"  é¢„ç•™: {reserved:.1f}MB ({metrics.get('memory_reserved_percent', 0):.1f}%)")
            
            # GPU ä½¿ç”¨ç‡
            if 'utilization_gpu_percent' in metrics:
                print(f"  GPU ä½¿ç”¨ç‡: {metrics['utilization_gpu_percent']}%")
                print(f"  æ˜¾å­˜ä½¿ç”¨ç‡: {metrics['utilization_memory_percent']}%")
            
            # æ¸©åº¦
            if 'temperature_celsius' in metrics and metrics['temperature_celsius'] is not None:
                print(f"  æ¸©åº¦: {metrics['temperature_celsius']}Â°C")
            
            # åŠŸè€—
            if 'power_usage_watts' in metrics and metrics['power_usage_watts'] is not None:
                power = metrics['power_usage_watts']
                limit = metrics.get('power_limit_watts')
                pct = metrics.get('power_usage_percent')
                if limit:
                    print(f"  åŠŸè€—: {power:.1f}W / {limit:.1f}W ({pct:.1f}%)" if pct else f"  åŠŸè€—: {power:.1f}W / {limit:.1f}W")
                else:
                    print(f"  åŠŸè€—: {power:.1f}W")
        
        print("="*60 + "\n")

